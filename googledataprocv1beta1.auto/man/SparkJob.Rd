% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataproc_objects.R
\name{SparkJob}
\alias{SparkJob}
\title{Google Cloud Dataproc API Objects 
Manages Hadoop-based clusters and jobs on Google Cloud Platform.}
\usage{
SparkJob(SparkJob.properties = NULL, jarFileUris = NULL,
  loggingConfiguration = NULL, properties = NULL, args = NULL,
  fileUris = NULL, mainClass = NULL, archiveUris = NULL,
  mainJarFileUri = NULL)
}
\arguments{
\item{SparkJob.properties}{The \link{SparkJob.properties} object or list of objects}

\item{jarFileUris}{Optional HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks}

\item{loggingConfiguration}{Optional The runtime log configuration for job execution}

\item{properties}{Optional A mapping of property names to values, used to configure Spark}

\item{args}{Optional The arguments to pass to the driver}

\item{fileUris}{Optional HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks}

\item{mainClass}{The name of the driver's main class}

\item{archiveUris}{Optional HCFS URIs of archives to be extracted in the working directory of Spark drivers and tasks}

\item{mainJarFileUri}{The Hadoop Compatible Filesystem (HCFS) URI of the jar file that contains the main class}
}
\value{
SparkJob object
}
\description{
Auto-generated code by googleAuthR::gar_create_api_objects
 at 2017-03-05 19:43:02
filename: /Users/mark/dev/R/autoGoogleAPI/googledataprocv1beta1.auto/R/dataproc_objects.R
api_json: api_json
}
\details{
Objects for use by the functions created by googleAuthR::gar_create_api_skeleton
SparkJob Object


Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
A Cloud Dataproc job for running Spark applications on YARN.
}
\seealso{
Other SparkJob functions: \code{\link{SparkJob.properties}}
}
