% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/genomics_objects.R
\name{PipelineParameter}
\alias{PipelineParameter}
\title{PipelineParameter Object}
\usage{
PipelineParameter(defaultValue = NULL, name = NULL, description = NULL,
  localCopy = NULL)
}
\arguments{
\item{defaultValue}{The default value for this parameter}

\item{name}{Required}

\item{description}{Human-readable description}

\item{localCopy}{If present, this parameter is marked for copying to and from the VM}
}
\value{
PipelineParameter object
}
\description{
PipelineParameter Object
}
\details{
Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
Parameters facilitate setting and delivering data into thepipeline's execution environment. They are defined at create time,with optional defaults, and can be overridden at run time.If `localCopy` is unset, then the parameter specifies a string thatis passed as-is into the pipeline, as the value of the environmentvariable with the given name.  A default value can be optionallyspecified at create time. The default can be overridden at run timeusing the inputs map. If no default is given, a value must besupplied at runtime.If `localCopy` is defined, then the parameter specifies a datasource or sink, both in Google Cloud Storage and on the Docker containerwhere the pipeline computation is run. The service account associated withthe Pipeline (bydefault the project's Compute Engine service account) must have access to theGoogle Cloud Storage paths.At run time, the Google Cloud Storage paths can be overridden if a defaultwas provided at create time, or must be set otherwise. The pipeline runnershould add a key/value pair to either the inputs or outputs map. Theindicated data copies will be carried out before/after pipeline execution,just as if the corresponding arguments were provided to `gsutil cp`.For example: Given the following `PipelineParameter`, specifiedin the `inputParameters` list:```{name: 'input_file', localCopy: {path: 'file.txt', disk: 'pd1'}}```where `disk` is defined in the `PipelineResources` object as:```{name: 'pd1', mountPoint: '/mnt/disk/'}```We create a disk named `pd1`, mount it on the host VM, and map`/mnt/pd1` to `/mnt/disk` in the docker container.  Atruntime, an entry for `input_file` would be required in the inputsmap, such as:```  inputs['input_file'] = 'gs://my-bucket/bar.txt'```This would generate the following gsutil call:```  gsutil cp gs://my-bucket/bar.txt /mnt/pd1/file.txt```The file `/mnt/pd1/file.txt` maps to `/mnt/disk/file.txt` in theDocker container. Acceptable paths are:<table>  <thead>    <tr><th>Google Cloud storage path</th><th>Local path</th></tr>  </thead>  <tbody>    <tr><td>file</td><td>file</td></tr>    <tr><td>glob</td><td>directory</td></tr>  </tbody></table>For outputs, the direction of the copy is reversed:```  gsutil cp /mnt/disk/file.txt gs://my-bucket/bar.txt```Acceptable paths are:<table>  <thead>    <tr><th>Local path</th><th>Google Cloud Storage path</th></tr>  </thead>  <tbody>    <tr><td>file</td><td>file</td></tr>    <tr>      <td>file</td>      <td>directory - directory must already exist</td>    </tr>    <tr>      <td>glob</td>      <td>directory - directory will be created if it doesn't exist</td></tr>  </tbody></table>One restriction due to docker limitations, is that for outputs that are foundon the boot disk, the local path cannot be a glob and must be a file.
}
