#' Google Cloud Vision API Objects 
#' Integrates Google Vision features, including image labeling, face, logo, and landmark detection, optical character recognition (OCR), and detection of explicit content, into applications.
#' 
#' Auto-generated code by googleAuthR::gar_create_api_objects
#'  at 2017-03-05 20:21:48
#' filename: /Users/mark/dev/R/autoGoogleAPI/googlevisionv1.auto/R/vision_objects.R
#' api_json: api_json
#' 
#' Objects for use by the functions created by googleAuthR::gar_create_api_skeleton

#' BatchAnnotateImagesRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Multiple image annotation requests are batched into a single service call.
#' 
#' @param requests Individual image annotation requests for this batch
#' 
#' @return BatchAnnotateImagesRequest object
#' 
#' @family BatchAnnotateImagesRequest functions
#' @export
BatchAnnotateImagesRequest <- function(requests = NULL) {
    structure(list(requests = requests), class = "gar_BatchAnnotateImagesRequest")
}

#' DetectedBreak Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Detected start or end of a structural component.
#' 
#' @param type Detected break type
#' @param isPrefix True if break prepends the element
#' 
#' @return DetectedBreak object
#' 
#' @family DetectedBreak functions
#' @export
DetectedBreak <- function(type = NULL, isPrefix = NULL) {
    structure(list(type = type, isPrefix = isPrefix), class = "gar_DetectedBreak")
}

#' ImageContext Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Image context and/or feature-specific parameters.
#' 
#' @param languageHints List of languages to use for TEXT_DETECTION
#' @param latLongRect lat/long rectangle that specifies the location of the image
#' @param cropHintsParams Parameters for crop hints annotation request
#' 
#' @return ImageContext object
#' 
#' @family ImageContext functions
#' @export
ImageContext <- function(languageHints = NULL, latLongRect = NULL, cropHintsParams = NULL) {
    structure(list(languageHints = languageHints, latLongRect = latLongRect, cropHintsParams = cropHintsParams), 
        class = "gar_ImageContext")
}

#' Page Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Detected page from OCR.
#' 
#' @param height Page height in pixels
#' @param width Page width in pixels
#' @param blocks List of blocks of text, images etc on this page
#' @param property Additional information detected on the page
#' 
#' @return Page object
#' 
#' @family Page functions
#' @export
Page <- function(height = NULL, width = NULL, blocks = NULL, property = NULL) {
    structure(list(height = height, width = width, blocks = blocks, property = property), 
        class = "gar_Page")
}

#' AnnotateImageRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request for performing Google Cloud Vision API tasks over a user-providedimage, with user-requested features.
#' 
#' @param image The image to be processed
#' @param features Requested features
#' @param imageContext Additional context that may accompany the image
#' 
#' @return AnnotateImageRequest object
#' 
#' @family AnnotateImageRequest functions
#' @export
AnnotateImageRequest <- function(image = NULL, features = NULL, imageContext = NULL) {
    structure(list(image = image, features = features, imageContext = imageContext), 
        class = "gar_AnnotateImageRequest")
}

#' Status Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The `Status` type defines a logical error model that is suitable for differentprogramming environments, including REST APIs and RPC APIs. It is used by[gRPC](https://github.com/grpc). The error model is designed to be:- Simple to use and understand for most users- Flexible enough to meet unexpected needs# OverviewThe `Status` message contains three pieces of data: error code, error message,and error details. The error code should be an enum value ofgoogle.rpc.Code, but it may accept additional error codes if needed.  Theerror message should be a developer-facing English message that helpsdevelopers *understand* and *resolve* the error. If a localized user-facingerror message is needed, put the localized message in the error details orlocalize it in the client. The optional error details may contain arbitraryinformation about the error. There is a predefined set of error detail typesin the package `google.rpc` which can be used for common error conditions.# Language mappingThe `Status` message is the logical representation of the error model, but itis not necessarily the actual wire format. When the `Status` message isexposed in different client libraries and different wire protocols, it can bemapped differently. For example, it will likely be mapped to some exceptionsin Java, but more likely mapped to some error codes in C.# Other usesThe error model and the `Status` message can be used in a variety ofenvironments, either with or without APIs, to provide aconsistent developer experience across different environments.Example uses of this error model include:- Partial errors. If a service needs to return partial errors to the client,    it may embed the `Status` in the normal response to indicate the partial    errors.- Workflow errors. A typical workflow has multiple steps. Each step may    have a `Status` message for error reporting purpose.- Batch operations. If a client uses batch request and batch response, the    `Status` message should be used directly inside batch response, one for    each error sub-response.- Asynchronous operations. If an API call embeds asynchronous operation    results in its response, the status of those operations should be    represented directly using the `Status` message.- Logging. If some API errors are stored in logs, the message `Status` could    be used directly after any stripping needed for security/privacy reasons.
#' 
#' @param message A developer-facing error message, which should be in English
#' @param details A list of messages that carry the error details
#' @param code The status code, which should be an enum value of google
#' 
#' @return Status object
#' 
#' @family Status functions
#' @export
Status <- function(message = NULL, details = NULL, code = NULL) {
    structure(list(message = message, details = details, code = code), class = "gar_Status")
}

#' LatLongRect Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Rectangle determined by min and max `LatLng` pairs.
#' 
#' @param minLatLng Min lat/long pair
#' @param maxLatLng Max lat/long pair
#' 
#' @return LatLongRect object
#' 
#' @family LatLongRect functions
#' @export
LatLongRect <- function(minLatLng = NULL, maxLatLng = NULL) {
    structure(list(minLatLng = minLatLng, maxLatLng = maxLatLng), class = "gar_LatLongRect")
}

#' Symbol Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A single symbol representation.
#' 
#' @param text The actual UTF-8 representation of the symbol
#' @param property Additional information detected for the symbol
#' @param boundingBox The bounding box for the symbol
#' 
#' @return Symbol object
#' 
#' @family Symbol functions
#' @export
Symbol <- function(text = NULL, property = NULL, boundingBox = NULL) {
    structure(list(text = text, property = property, boundingBox = boundingBox), 
        class = "gar_Symbol")
}

#' CropHintsAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Set of crop hints that are used to generate new crops when serving images.
#' 
#' @param cropHints Crop hint results
#' 
#' @return CropHintsAnnotation object
#' 
#' @family CropHintsAnnotation functions
#' @export
CropHintsAnnotation <- function(cropHints = NULL) {
    structure(list(cropHints = cropHints), class = "gar_CropHintsAnnotation")
}

#' LatLng Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' An object representing a latitude/longitude pair. This is expressed as a pairof doubles representing degrees latitude and degrees longitude. Unlessspecified otherwise, this must conform to the<a href='http://www.unoosa.org/pdf/icg/2012/template/WGS_84.pdf'>WGS84standard</a>. Values must be within normalized ranges.Example of normalization code in Python:    def NormalizeLongitude(longitude):      '''Wraps decimal degrees longitude to [-180.0, 180.0].'''      q, r = divmod(longitude, 360.0)      if r > 180.0 or (r == 180.0 and q <= -1.0):        return r - 360.0      return r    def NormalizeLatLng(latitude, longitude):      '''Wraps decimal degrees latitude and longitude to      [-90.0, 90.0] and [-180.0, 180.0], respectively.'''      r = latitude % 360.0      if r <= 90.0:        return r, NormalizeLongitude(longitude)      elif r >= 270.0:        return r - 360, NormalizeLongitude(longitude)      else:        return 180 - r, NormalizeLongitude(longitude + 180.0)    assert 180.0 == NormalizeLongitude(180.0)    assert -180.0 == NormalizeLongitude(-180.0)    assert -179.0 == NormalizeLongitude(181.0)    assert (0.0, 0.0) == NormalizeLatLng(360.0, 0.0)    assert (0.0, 0.0) == NormalizeLatLng(-360.0, 0.0)    assert (85.0, 180.0) == NormalizeLatLng(95.0, 0.0)    assert (-85.0, -170.0) == NormalizeLatLng(-95.0, 10.0)    assert (90.0, 10.0) == NormalizeLatLng(90.0, 10.0)    assert (-90.0, -10.0) == NormalizeLatLng(-90.0, -10.0)    assert (0.0, -170.0) == NormalizeLatLng(-180.0, 10.0)    assert (0.0, -170.0) == NormalizeLatLng(180.0, 10.0)    assert (-90.0, 10.0) == NormalizeLatLng(270.0, 10.0)    assert (90.0, 10.0) == NormalizeLatLng(-270.0, 10.0)The code in logs/storage/validator/logs_validator_traits.cc treats this typeas if it were annotated as ST_LOCATION.
#' 
#' @param latitude The latitude in degrees
#' @param longitude The longitude in degrees
#' 
#' @return LatLng object
#' 
#' @family LatLng functions
#' @export
LatLng <- function(latitude = NULL, longitude = NULL) {
    structure(list(latitude = latitude, longitude = longitude), class = "gar_LatLng")
}

#' Color Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Represents a color in the RGBA color space. This representation is designedfor simplicity of conversion to/from color representations in variouslanguages over compactness; for example, the fields of this representationcan be trivially provided to the constructor of 'java.awt.Color' in Java; itcan also be trivially provided to UIColor's '+colorWithRed:green:blue:alpha'method in iOS; and, with just a little work, it can be easily formatted intoa CSS 'rgba()' string in JavaScript, as well. Here are some examples:Example (Java):     import com.google.type.Color;     // ...     public static java.awt.Color fromProto(Color protocolor) {       float alpha = protocolor.hasAlpha()           ? protocolor.getAlpha().getValue()           : 1.0;       return new java.awt.Color(           protocolor.getRed(),           protocolor.getGreen(),           protocolor.getBlue(),           alpha);     }     public static Color toProto(java.awt.Color color) {       float red = (float) color.getRed();       float green = (float) color.getGreen();       float blue = (float) color.getBlue();       float denominator = 255.0;       Color.Builder resultBuilder =           Color               .newBuilder()               .setRed(red / denominator)               .setGreen(green / denominator)               .setBlue(blue / denominator);       int alpha = color.getAlpha();       if (alpha != 255) {         result.setAlpha(             FloatValue                 .newBuilder()                 .setValue(((float) alpha) / denominator)                 .build());       }       return resultBuilder.build();     }     // ...Example (iOS / Obj-C):     // ...     static UIColor* fromProto(Color* protocolor) {        float red = [protocolor red];        float green = [protocolor green];        float blue = [protocolor blue];        FloatValue* alpha_wrapper = [protocolor alpha];        float alpha = 1.0;        if (alpha_wrapper != nil) {          alpha = [alpha_wrapper value];        }        return [UIColor colorWithRed:red green:green blue:blue alpha:alpha];     }     static Color* toProto(UIColor* color) {         CGFloat red, green, blue, alpha;         if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) {           return nil;         }         Color* result = [Color alloc] init];         [result setRed:red];         [result setGreen:green];         [result setBlue:blue];         if (alpha <= 0.9999) {           [result setAlpha:floatWrapperWithValue(alpha)];         }         [result autorelease];         return result;    }    // ... Example (JavaScript):    // ...    var protoToCssColor = function(rgb_color) {       var redFrac = rgb_color.red || 0.0;       var greenFrac = rgb_color.green || 0.0;       var blueFrac = rgb_color.blue || 0.0;       var red = Math.floor(redFrac * 255);       var green = Math.floor(greenFrac * 255);       var blue = Math.floor(blueFrac * 255);       if (!('alpha' in rgb_color)) {          return rgbToCssColor_(red, green, blue);       }       var alphaFrac = rgb_color.alpha.value || 0.0;       var rgbParams = [red, green, blue].join(',');       return ['rgba(', rgbParams, ',', alphaFrac, ')'].join('');    };    var rgbToCssColor_ = function(red, green, blue) {      var rgbNumber = new Number((red << 16) | (green << 8) | blue);      var hexString = rgbNumber.toString(16);      var missingZeros = 6 - hexString.length;      var resultBuilder = ['#'];      for (var i = 0; i < missingZeros; i++) {         resultBuilder.push('0');      }      resultBuilder.push(hexString);      return resultBuilder.join('');    };    // ...
#' 
#' @param red The amount of red in the color as a value in the interval [0, 1]
#' @param green The amount of green in the color as a value in the interval [0, 1]
#' @param blue The amount of blue in the color as a value in the interval [0, 1]
#' @param alpha The fraction of this color that should be applied to the pixel
#' 
#' @return Color object
#' 
#' @family Color functions
#' @export
Color <- function(red = NULL, green = NULL, blue = NULL, alpha = NULL) {
    structure(list(red = red, green = green, blue = blue, alpha = alpha), class = "gar_Color")
}

#' Feature Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Users describe the type of Google Cloud Vision API tasks to perform overimages by using *Feature*s. Each Feature indicates a type of imagedetection task to perform. Features encode the Cloud Vision APIvertical to operate on and the number of top-scoring results to return.
#' 
#' @param type The feature type
#' @param maxResults Maximum number of results of this type
#' 
#' @return Feature object
#' 
#' @family Feature functions
#' @export
Feature <- function(type = NULL, maxResults = NULL) {
    structure(list(type = type, maxResults = maxResults), class = "gar_Feature")
}

#' ImageProperties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Stores image properties, such as dominant colors.
#' 
#' @param dominantColors If present, dominant colors completed successfully
#' 
#' @return ImageProperties object
#' 
#' @family ImageProperties functions
#' @export
ImageProperties <- function(dominantColors = NULL) {
    structure(list(dominantColors = dominantColors), class = "gar_ImageProperties")
}

#' SafeSearchAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Set of features pertaining to the image, computed by computer visionmethods over safe-search verticals (for example, adult, spoof, medical,violence).
#' 
#' @param violence Violence likelihood
#' @param adult Represents the adult content likelihood for the image
#' @param spoof Spoof likelihood
#' @param medical Likelihood that this is a medical image
#' 
#' @return SafeSearchAnnotation object
#' 
#' @family SafeSearchAnnotation functions
#' @export
SafeSearchAnnotation <- function(violence = NULL, adult = NULL, spoof = NULL, medical = NULL) {
    structure(list(violence = violence, adult = adult, spoof = spoof, medical = medical), 
        class = "gar_SafeSearchAnnotation")
}

#' DominantColorsAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Set of dominant colors and their corresponding scores.
#' 
#' @param colors RGB color values with their score and pixel fraction
#' 
#' @return DominantColorsAnnotation object
#' 
#' @family DominantColorsAnnotation functions
#' @export
DominantColorsAnnotation <- function(colors = NULL) {
    structure(list(colors = colors), class = "gar_DominantColorsAnnotation")
}

#' TextAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' TextAnnotation contains a structured representation of OCR extracted text.The hierarchy of an OCR extracted text structure is like this:    TextAnnotation -> Page -> Block -> Paragraph -> Word -> SymbolEach structural component, starting from Page, may further have their ownproperties. Properties describe detected languages, breaks etc.. Pleaserefer to the google.cloud.vision.v1.TextAnnotation.TextProperty messagedefinition below for more detail.
#' 
#' @param pages List of pages detected by OCR
#' @param text UTF-8 text detected on the pages
#' 
#' @return TextAnnotation object
#' 
#' @family TextAnnotation functions
#' @export
TextAnnotation <- function(pages = NULL, text = NULL) {
    structure(list(pages = pages, text = text), class = "gar_TextAnnotation")
}

#' Vertex Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A vertex represents a 2D point in the image.NOTE: the vertex coordinates are in the same scale as the original image.
#' 
#' @param y Y coordinate
#' @param x X coordinate
#' 
#' @return Vertex object
#' 
#' @family Vertex functions
#' @export
Vertex <- function(y = NULL, x = NULL) {
    structure(list(y = y, x = x), class = "gar_Vertex")
}

#' DetectedLanguage Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Detected language for a structural component.
#' 
#' @param languageCode The BCP-47 language code, such as 'en-US' or 'sr-Latn'
#' @param confidence Confidence of detected language
#' 
#' @return DetectedLanguage object
#' 
#' @family DetectedLanguage functions
#' @export
DetectedLanguage <- function(languageCode = NULL, confidence = NULL) {
    structure(list(languageCode = languageCode, confidence = confidence), class = "gar_DetectedLanguage")
}

#' TextProperty Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional information detected on the structural component.
#' 
#' @param detectedBreak Detected start or end of a text segment
#' @param detectedLanguages A list of detected languages together with confidence
#' 
#' @return TextProperty object
#' 
#' @family TextProperty functions
#' @export
TextProperty <- function(detectedBreak = NULL, detectedLanguages = NULL) {
    structure(list(detectedBreak = detectedBreak, detectedLanguages = detectedLanguages), 
        class = "gar_TextProperty")
}

#' BoundingPoly Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A bounding polygon for the detected image annotation.
#' 
#' @param vertices The bounding polygon vertices
#' 
#' @return BoundingPoly object
#' 
#' @family BoundingPoly functions
#' @export
BoundingPoly <- function(vertices = NULL) {
    structure(list(vertices = vertices), class = "gar_BoundingPoly")
}

#' WebEntity Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Entity deduced from similar images on the Internet.
#' 
#' @param entityId Opaque entity ID
#' @param description Canonical description of the entity, in English
#' @param score Overall relevancy score for the entity
#' 
#' @return WebEntity object
#' 
#' @family WebEntity functions
#' @export
WebEntity <- function(entityId = NULL, description = NULL, score = NULL) {
    structure(list(entityId = entityId, description = description, score = score), 
        class = "gar_WebEntity")
}

#' AnnotateImageResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response to an image annotation request.
#' 
#' @param cropHintsAnnotation If present, crop hints have completed successfully
#' @param webDetection If present, web detection has completed successfully
#' @param labelAnnotations If present, label detection has completed successfully
#' @param safeSearchAnnotation If present, safe-search annotation has completed successfully
#' @param error If set, represents the error message for the operation
#' @param fullTextAnnotation If present, text (OCR) detection or document (OCR) text detection has
#' @param landmarkAnnotations If present, landmark detection has completed successfully
#' @param textAnnotations If present, text (OCR) detection has completed successfully
#' @param imagePropertiesAnnotation If present, image properties were extracted successfully
#' @param faceAnnotations If present, face detection has completed successfully
#' @param logoAnnotations If present, logo detection has completed successfully
#' 
#' @return AnnotateImageResponse object
#' 
#' @family AnnotateImageResponse functions
#' @export
AnnotateImageResponse <- function(cropHintsAnnotation = NULL, webDetection = NULL, 
    labelAnnotations = NULL, safeSearchAnnotation = NULL, error = NULL, fullTextAnnotation = NULL, 
    landmarkAnnotations = NULL, textAnnotations = NULL, imagePropertiesAnnotation = NULL, 
    faceAnnotations = NULL, logoAnnotations = NULL) {
    structure(list(cropHintsAnnotation = cropHintsAnnotation, webDetection = webDetection, 
        labelAnnotations = labelAnnotations, safeSearchAnnotation = safeSearchAnnotation, 
        error = error, fullTextAnnotation = fullTextAnnotation, landmarkAnnotations = landmarkAnnotations, 
        textAnnotations = textAnnotations, imagePropertiesAnnotation = imagePropertiesAnnotation, 
        faceAnnotations = faceAnnotations, logoAnnotations = logoAnnotations), class = "gar_AnnotateImageResponse")
}

#' CropHintsParams Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Parameters for crop hints annotation request.
#' 
#' @param aspectRatios Aspect ratios in floats, representing the ratio of the width to the height
#' 
#' @return CropHintsParams object
#' 
#' @family CropHintsParams functions
#' @export
CropHintsParams <- function(aspectRatios = NULL) {
    structure(list(aspectRatios = aspectRatios), class = "gar_CropHintsParams")
}

#' Block Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Logical element on the page.
#' 
#' @param property Additional information detected for the block
#' @param blockType Detected block type (text, image etc) for this block
#' @param boundingBox The bounding box for the block
#' @param paragraphs List of paragraphs in this block (if this blocks is of type text)
#' 
#' @return Block object
#' 
#' @family Block functions
#' @export
Block <- function(property = NULL, blockType = NULL, boundingBox = NULL, paragraphs = NULL) {
    structure(list(property = property, blockType = blockType, boundingBox = boundingBox, 
        paragraphs = paragraphs), class = "gar_Block")
}

#' LocationInfo Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Detected entity location information.
#' 
#' @param latLng lat/long location coordinates
#' 
#' @return LocationInfo object
#' 
#' @family LocationInfo functions
#' @export
LocationInfo <- function(latLng = NULL) {
    structure(list(latLng = latLng), class = "gar_LocationInfo")
}

#' ImageSource Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' External image source (Google Cloud Storage image location).
#' 
#' @param gcsImageUri NOTE: For new code `image_uri` below is preferred
#' @param imageUri Image URI which supports:
#' 
#' @return ImageSource object
#' 
#' @family ImageSource functions
#' @export
ImageSource <- function(gcsImageUri = NULL, imageUri = NULL) {
    structure(list(gcsImageUri = gcsImageUri, imageUri = imageUri), class = "gar_ImageSource")
}

#' BatchAnnotateImagesResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response to a batch image annotation request.
#' 
#' @param responses Individual responses to image annotation requests within the batch
#' 
#' @return BatchAnnotateImagesResponse object
#' 
#' @family BatchAnnotateImagesResponse functions
#' @export
BatchAnnotateImagesResponse <- function(responses = NULL) {
    structure(list(responses = responses), class = "gar_BatchAnnotateImagesResponse")
}

#' Property Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A `Property` consists of a user-supplied name/value pair.
#' 
#' @param value Value of the property
#' @param uint64Value Value of numeric properties
#' @param name Name of the property
#' 
#' @return Property object
#' 
#' @family Property functions
#' @export
Property <- function(value = NULL, uint64Value = NULL, name = NULL) {
    structure(list(value = value, uint64Value = uint64Value, name = name), class = "gar_Property")
}

#' WebDetection Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Relevant information for the image from the Internet.
#' 
#' @param fullMatchingImages Fully matching images from the Internet
#' @param webEntities Deduced entities from similar images on the Internet
#' @param pagesWithMatchingImages Web pages containing the matching images from the Internet
#' @param partialMatchingImages Partial matching images from the Internet
#' 
#' @return WebDetection object
#' 
#' @family WebDetection functions
#' @export
WebDetection <- function(fullMatchingImages = NULL, webEntities = NULL, pagesWithMatchingImages = NULL, 
    partialMatchingImages = NULL) {
    structure(list(fullMatchingImages = fullMatchingImages, webEntities = webEntities, 
        pagesWithMatchingImages = pagesWithMatchingImages, partialMatchingImages = partialMatchingImages), 
        class = "gar_WebDetection")
}

#' Position Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A 3D position in the image, used primarily for Face detection landmarks.A valid Position must have both x and y coordinates.The position coordinates are in the same scale as the original image.
#' 
#' @param y Y coordinate
#' @param x X coordinate
#' @param z Z coordinate (or depth)
#' 
#' @return Position object
#' 
#' @family Position functions
#' @export
Position <- function(y = NULL, x = NULL, z = NULL) {
    structure(list(y = y, x = x, z = z), class = "gar_Position")
}

#' WebPage Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata for web pages.
#' 
#' @param url The result web page URL
#' @param score Overall relevancy score for the web page
#' 
#' @return WebPage object
#' 
#' @family WebPage functions
#' @export
WebPage <- function(url = NULL, score = NULL) {
    structure(list(url = url, score = score), class = "gar_WebPage")
}

#' ColorInfo Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Color information consists of RGB channels, score, and the fraction ofthe image that the color occupies in the image.
#' 
#' @param pixelFraction The fraction of pixels the color occupies in the image
#' @param color RGB components of the color
#' @param score Image-specific score for this color
#' 
#' @return ColorInfo object
#' 
#' @family ColorInfo functions
#' @export
ColorInfo <- function(pixelFraction = NULL, color = NULL, score = NULL) {
    structure(list(pixelFraction = pixelFraction, color = color, score = score), 
        class = "gar_ColorInfo")
}

#' EntityAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Set of detected entity features.
#' 
#' @param boundingPoly Image region to which this entity belongs
#' @param locale The language code for the locale in which the entity textual
#' @param topicality The relevancy of the ICA (Image Content Annotation) label to the
#' @param description Entity textual description, expressed in its `locale` language
#' @param properties Some entities may have optional user-supplied `Property` (name/value)
#' @param score Overall score of the result
#' @param locations The location information for the detected entity
#' @param mid Opaque entity ID
#' @param confidence The accuracy of the entity detection in an image
#' 
#' @return EntityAnnotation object
#' 
#' @family EntityAnnotation functions
#' @export
EntityAnnotation <- function(boundingPoly = NULL, locale = NULL, topicality = NULL, 
    description = NULL, properties = NULL, score = NULL, locations = NULL, mid = NULL, 
    confidence = NULL) {
    structure(list(boundingPoly = boundingPoly, locale = locale, topicality = topicality, 
        description = description, properties = properties, score = score, locations = locations, 
        mid = mid, confidence = confidence), class = "gar_EntityAnnotation")
}

#' CropHint Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Single crop hint that is used to generate a new crop when serving an image.
#' 
#' @param boundingPoly The bounding polygon for the crop region
#' @param confidence Confidence of this being a salient region
#' @param importanceFraction Fraction of importance of this salient region with respect to the original
#' 
#' @return CropHint object
#' 
#' @family CropHint functions
#' @export
CropHint <- function(boundingPoly = NULL, confidence = NULL, importanceFraction = NULL) {
    structure(list(boundingPoly = boundingPoly, confidence = confidence, importanceFraction = importanceFraction), 
        class = "gar_CropHint")
}

#' Landmark Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A face-specific landmark (for example, a face feature).Landmark positions may fall outside the bounds of the imageif the face is near one or more edges of the image.Therefore it is NOT guaranteed that `0 <= x < width` or`0 <= y < height`.
#' 
#' @param position Face landmark position
#' @param type Face landmark type
#' 
#' @return Landmark object
#' 
#' @family Landmark functions
#' @export
Landmark <- function(position = NULL, type = NULL) {
    structure(list(position = position, type = type), class = "gar_Landmark")
}

#' WebImage Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata for online images.
#' 
#' @param score Overall relevancy score for the image
#' @param url The result image URL
#' 
#' @return WebImage object
#' 
#' @family WebImage functions
#' @export
WebImage <- function(score = NULL, url = NULL) {
    structure(list(score = score, url = url), class = "gar_WebImage")
}

#' Word Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A word representation.
#' 
#' @param property Additional information detected for the word
#' @param boundingBox The bounding box for the word
#' @param symbols List of symbols in the word
#' 
#' @return Word object
#' 
#' @family Word functions
#' @export
Word <- function(property = NULL, boundingBox = NULL, symbols = NULL) {
    structure(list(property = property, boundingBox = boundingBox, symbols = symbols), 
        class = "gar_Word")
}

#' Image Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Client image to perform Google Cloud Vision API tasks over.
#' 
#' @param content Image content, represented as a stream of bytes
#' @param source Google Cloud Storage image location
#' 
#' @return Image object
#' 
#' @family Image functions
#' @export
Image <- function(content = NULL, source = NULL) {
    structure(list(content = content, source = source), class = "gar_Image")
}

#' Paragraph Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Structural unit of text representing a number of words in certain order.
#' 
#' @param words List of words in this paragraph
#' @param property Additional information detected for the paragraph
#' @param boundingBox The bounding box for the paragraph
#' 
#' @return Paragraph object
#' 
#' @family Paragraph functions
#' @export
Paragraph <- function(words = NULL, property = NULL, boundingBox = NULL) {
    structure(list(words = words, property = property, boundingBox = boundingBox), 
        class = "gar_Paragraph")
}


#' FaceAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A face annotation object contains the results of face detection.
#' 
#' @param fdBoundingPoly The `fd_bounding_poly` bounding polygon is tighter than the
#' @param angerLikelihood Anger likelihood
#' @param landmarks Detected face landmarks
#' @param surpriseLikelihood Surprise likelihood
#' @param landmarkingConfidence Face landmarking confidence
#' @param joyLikelihood Joy likelihood
#' @param underExposedLikelihood Under-exposed likelihood
#' @param panAngle Yaw angle, which indicates the leftward/rightward angle that the face is
#' @param detectionConfidence Detection confidence
#' @param blurredLikelihood Blurred likelihood
#' @param headwearLikelihood Headwear likelihood
#' @param boundingPoly The bounding polygon around the face
#' @param rollAngle Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
#' @param sorrowLikelihood Sorrow likelihood
#' @param tiltAngle Pitch angle, which indicates the upwards/downwards angle that the face is
#' 
#' @return FaceAnnotation object
#' 
#' @family FaceAnnotation functions
#' @export


FaceAnnotation <- function(fdBoundingPoly = NULL, angerLikelihood = NULL, landmarks = NULL, 
    surpriseLikelihood = NULL, landmarkingConfidence = NULL, joyLikelihood = NULL, 
    underExposedLikelihood = NULL, panAngle = NULL, detectionConfidence = NULL, blurredLikelihood = NULL, 
    headwearLikelihood = NULL, boundingPoly = NULL, rollAngle = NULL, sorrowLikelihood = NULL, 
    tiltAngle = NULL) {
    
    
    
    structure(list(fdBoundingPoly = fdBoundingPoly, angerLikelihood = angerLikelihood, 
        landmarks = landmarks, surpriseLikelihood = surpriseLikelihood, landmarkingConfidence = landmarkingConfidence, 
        joyLikelihood = joyLikelihood, underExposedLikelihood = underExposedLikelihood, 
        panAngle = panAngle, detectionConfidence = detectionConfidence, blurredLikelihood = blurredLikelihood, 
        headwearLikelihood = headwearLikelihood, boundingPoly = boundingPoly, rollAngle = rollAngle, 
        sorrowLikelihood = sorrowLikelihood, tiltAngle = tiltAngle), class = "gar_FaceAnnotation")
}

