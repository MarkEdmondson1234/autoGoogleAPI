#' Google Cloud Dataproc API Objects 
#' Manages Hadoop-based clusters and jobs on Google Cloud Platform.
#' 
#' Auto-generated code by googleAuthR::gar_create_api_objects
#'  at 2017-03-05 19:42:37
#' filename: /Users/mark/dev/R/autoGoogleAPI/googledataprocv1.auto/R/dataproc_objects.R
#' api_json: api_json
#' 
#' Objects for use by the functions created by googleAuthR::gar_create_api_skeleton

#' ListClustersResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The list of all clusters in a project.
#' 
#' @param clusters Output-only The clusters in the project
#' @param nextPageToken Output-only This token is included in the response if there are more results to fetch
#' 
#' @return ListClustersResponse object
#' 
#' @family ListClustersResponse functions
#' @export
ListClustersResponse <- function(clusters = NULL, nextPageToken = NULL) {
    structure(list(clusters = clusters, nextPageToken = nextPageToken), class = "gar_ListClustersResponse")
}

#' SparkJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache Spark (http://spark.apache.org/) applications on YARN.
#' 
#' @param SparkJob.properties The \link{SparkJob.properties} object or list of objects
#' @param args Optional The arguments to pass to the driver
#' @param fileUris Optional HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks
#' @param mainClass The name of the driver's main class
#' @param archiveUris Optional HCFS URIs of archives to be extracted in the working directory of Spark drivers and tasks
#' @param mainJarFileUri The HCFS URI of the jar file that contains the main class
#' @param jarFileUris Optional HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks
#' @param loggingConfig Optional The runtime log config for job execution
#' @param properties Optional A mapping of property names to values, used to configure Spark
#' 
#' @return SparkJob object
#' 
#' @family SparkJob functions
#' @export
SparkJob <- function(SparkJob.properties = NULL, args = NULL, fileUris = NULL, mainClass = NULL, 
    archiveUris = NULL, mainJarFileUri = NULL, jarFileUris = NULL, loggingConfig = NULL, 
    properties = NULL) {
    structure(list(SparkJob.properties = SparkJob.properties, args = args, fileUris = fileUris, 
        mainClass = mainClass, archiveUris = archiveUris, mainJarFileUri = mainJarFileUri, 
        jarFileUris = jarFileUris, loggingConfig = loggingConfig, properties = properties), 
        class = "gar_SparkJob")
}

#' SparkJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
#' 
#' 
#' 
#' @return SparkJob.properties object
#' 
#' @family SparkJob functions
#' @export
SparkJob.properties <- function() {
    list()
}

#' Job Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job resource.
#' 
#' @param Job.labels The \link{Job.labels} object or list of objects
#' @param hadoopJob Job is a Hadoop job
#' @param placement Required Job information, including how, when, and where to run the job
#' @param status Output-only The job status
#' @param driverControlFilesUri Output-only If present, the location of miscellaneous control files which may be used as part of job setup and handling
#' @param scheduling Optional Job scheduling configuration
#' @param pigJob Job is a Pig job
#' @param hiveJob Job is a Hive job
#' @param labels Optional The labels to associate with this job
#' @param driverOutputResourceUri Output-only A URI pointing to the location of the stdout of the job's driver program
#' @param sparkJob Job is a Spark job
#' @param statusHistory Output-only The previous job status
#' @param sparkSqlJob Job is a SparkSql job
#' @param yarnApplications Output-only The collection of YARN applications spun up by this job
#' @param pysparkJob Job is a Pyspark job
#' @param reference Optional The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource
#' 
#' @return Job object
#' 
#' @family Job functions
#' @export
Job <- function(Job.labels = NULL, hadoopJob = NULL, placement = NULL, status = NULL, 
    driverControlFilesUri = NULL, scheduling = NULL, pigJob = NULL, hiveJob = NULL, 
    labels = NULL, driverOutputResourceUri = NULL, sparkJob = NULL, statusHistory = NULL, 
    sparkSqlJob = NULL, yarnApplications = NULL, pysparkJob = NULL, reference = NULL) {
    structure(list(Job.labels = Job.labels, hadoopJob = hadoopJob, placement = placement, 
        status = status, driverControlFilesUri = driverControlFilesUri, scheduling = scheduling, 
        pigJob = pigJob, hiveJob = hiveJob, labels = labels, driverOutputResourceUri = driverOutputResourceUri, 
        sparkJob = sparkJob, statusHistory = statusHistory, sparkSqlJob = sparkSqlJob, 
        yarnApplications = yarnApplications, pysparkJob = pysparkJob, reference = reference), 
        class = "gar_Job")
}

#' Job.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
#' 
#' 
#' 
#' @return Job.labels object
#' 
#' @family Job functions
#' @export
Job.labels <- function() {
    list()
}

#' JobStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Cloud Dataproc job status.
#' 
#' @param state Output-only A state message specifying the overall job state
#' @param details Output-only Optional job state details, such as an error description if the state is <code>ERROR</code>
#' @param stateStartTime Output-only The time when this state was entered
#' 
#' @return JobStatus object
#' 
#' @family JobStatus functions
#' @export
JobStatus <- function(state = NULL, details = NULL, stateStartTime = NULL) {
    structure(list(state = state, details = details, stateStartTime = stateStartTime), 
        class = "gar_JobStatus")
}

#' ManagedGroupConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the resources used to actively manage an instance group.
#' 
#' @param instanceGroupManagerName Output-only The name of the Instance Group Manager for this group
#' @param instanceTemplateName Output-only The name of the Instance Template used for the Managed Instance Group
#' 
#' @return ManagedGroupConfig object
#' 
#' @family ManagedGroupConfig functions
#' @export
ManagedGroupConfig <- function(instanceGroupManagerName = NULL, instanceTemplateName = NULL) {
    structure(list(instanceGroupManagerName = instanceGroupManagerName, instanceTemplateName = instanceTemplateName), 
        class = "gar_ManagedGroupConfig")
}

#' ClusterOperationStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of the operation.
#' 
#' @param state Output-only A message containing the operation state
#' @param details Output-onlyA message containing any operation metadata details
#' @param innerState Output-only A message containing the detailed operation state
#' @param stateStartTime Output-only The time this state was entered
#' 
#' @return ClusterOperationStatus object
#' 
#' @family ClusterOperationStatus functions
#' @export
ClusterOperationStatus <- function(state = NULL, details = NULL, innerState = NULL, 
    stateStartTime = NULL) {
    structure(list(state = state, details = details, innerState = innerState, stateStartTime = stateStartTime), 
        class = "gar_ClusterOperationStatus")
}

#' HadoopJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache Hadoop MapReduce (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) jobs on Apache Hadoop YARN (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
#' 
#' @param HadoopJob.properties The \link{HadoopJob.properties} object or list of objects
#' @param mainJarFileUri The HCFS URI of the jar file containing the main class
#' @param jarFileUris Optional Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks
#' @param loggingConfig Optional The runtime log config for job execution
#' @param properties Optional A mapping of property names to values, used to configure Hadoop
#' @param args Optional The arguments to pass to the driver
#' @param fileUris Optional HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks
#' @param mainClass The name of the driver's main class
#' @param archiveUris Optional HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks
#' 
#' @return HadoopJob object
#' 
#' @family HadoopJob functions
#' @export
HadoopJob <- function(HadoopJob.properties = NULL, mainJarFileUri = NULL, jarFileUris = NULL, 
    loggingConfig = NULL, properties = NULL, args = NULL, fileUris = NULL, mainClass = NULL, 
    archiveUris = NULL) {
    structure(list(HadoopJob.properties = HadoopJob.properties, mainJarFileUri = mainJarFileUri, 
        jarFileUris = jarFileUris, loggingConfig = loggingConfig, properties = properties, 
        args = args, fileUris = fileUris, mainClass = mainClass, archiveUris = archiveUris), 
        class = "gar_HadoopJob")
}

#' HadoopJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
#' 
#' 
#' 
#' @return HadoopJob.properties object
#' 
#' @family HadoopJob functions
#' @export
HadoopJob.properties <- function() {
    list()
}

#' QueryList Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A list of queries to run on a cluster.
#' 
#' @param queries Required The queries to execute
#' 
#' @return QueryList object
#' 
#' @family QueryList functions
#' @export
QueryList <- function(queries = NULL) {
    structure(list(queries = queries), class = "gar_QueryList")
}

#' YarnApplication Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A YARN application created by a job. Application information is a subset of <code>org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto</code>.Beta Feature: This report is available for testing purposes only. It may be changed before final release.
#' 
#' @param state Required The application state
#' @param name Required The application name
#' @param trackingUrl Optional The HTTP URL of the ApplicationMaster, HistoryServer, or TimelineServer that provides application-specific information
#' @param progress Required The numerical progress of the application, from 1 to 100
#' 
#' @return YarnApplication object
#' 
#' @family YarnApplication functions
#' @export
YarnApplication <- function(state = NULL, name = NULL, trackingUrl = NULL, progress = NULL) {
    structure(list(state = state, name = name, trackingUrl = trackingUrl, progress = progress), 
        class = "gar_YarnApplication")
}

#' DiagnoseClusterRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to collect cluster diagnostic information.
#' 
#' 
#' 
#' @return DiagnoseClusterRequest object
#' 
#' @family DiagnoseClusterRequest functions
#' @export
DiagnoseClusterRequest <- function() {
    list()
}

#' DiskConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the config of disk options for a group of VM instances.
#' 
#' @param numLocalSsds Optional Number of attached SSDs, from 0 to 4 (default is 0)
#' @param bootDiskSizeGb Optional Size in GB of the boot disk (default is 500GB)
#' 
#' @return DiskConfig object
#' 
#' @family DiskConfig functions
#' @export
DiskConfig <- function(numLocalSsds = NULL, bootDiskSizeGb = NULL) {
    structure(list(numLocalSsds = numLocalSsds, bootDiskSizeGb = bootDiskSizeGb), 
        class = "gar_DiskConfig")
}

#' ClusterOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata describing the operation.
#' 
#' @param ClusterOperationMetadata.labels The \link{ClusterOperationMetadata.labels} object or list of objects
#' @param operationType Output-only The operation type
#' @param description Output-only Short description of operation
#' @param warnings Output-only Errors encountered during operation execution
#' @param labels Output-only Labels associated with the operation
#' @param status Output-only Current operation status
#' @param statusHistory Output-only The previous operation status
#' @param clusterUuid Output-only Cluster UUID for the operation
#' @param clusterName Output-only Name of the cluster for the operation
#' 
#' @return ClusterOperationMetadata object
#' 
#' @family ClusterOperationMetadata functions
#' @export
ClusterOperationMetadata <- function(ClusterOperationMetadata.labels = NULL, operationType = NULL, 
    description = NULL, warnings = NULL, labels = NULL, status = NULL, statusHistory = NULL, 
    clusterUuid = NULL, clusterName = NULL) {
    structure(list(ClusterOperationMetadata.labels = ClusterOperationMetadata.labels, 
        operationType = operationType, description = description, warnings = warnings, 
        labels = labels, status = status, statusHistory = statusHistory, clusterUuid = clusterUuid, 
        clusterName = clusterName), class = "gar_ClusterOperationMetadata")
}

#' ClusterOperationMetadata.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Output-only Labels associated with the operation
#' 
#' 
#' 
#' @return ClusterOperationMetadata.labels object
#' 
#' @family ClusterOperationMetadata functions
#' @export
ClusterOperationMetadata.labels <- function() {
    list()
}

#' HiveJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache Hive (https://hive.apache.org/) queries on YARN.
#' 
#' @param HiveJob.scriptVariables The \link{HiveJob.scriptVariables} object or list of objects
#' @param HiveJob.properties The \link{HiveJob.properties} object or list of objects
#' @param continueOnFailure Optional Whether to continue executing queries if a query fails
#' @param queryList A list of queries
#' @param queryFileUri The HCFS URI of the script that contains Hive queries
#' @param scriptVariables Optional Mapping of query variable names to values (equivalent to the Hive command: SET name='value';)
#' @param jarFileUris Optional HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks
#' @param properties Optional A mapping of property names and values, used to configure Hive
#' 
#' @return HiveJob object
#' 
#' @family HiveJob functions
#' @export
HiveJob <- function(HiveJob.scriptVariables = NULL, HiveJob.properties = NULL, continueOnFailure = NULL, 
    queryList = NULL, queryFileUri = NULL, scriptVariables = NULL, jarFileUris = NULL, 
    properties = NULL) {
    structure(list(HiveJob.scriptVariables = HiveJob.scriptVariables, HiveJob.properties = HiveJob.properties, 
        continueOnFailure = continueOnFailure, queryList = queryList, queryFileUri = queryFileUri, 
        scriptVariables = scriptVariables, jarFileUris = jarFileUris, properties = properties), 
        class = "gar_HiveJob")
}

#' HiveJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional Mapping of query variable names to values (equivalent to the Hive command: SET name='value';).
#' 
#' 
#' 
#' @return HiveJob.scriptVariables object
#' 
#' @family HiveJob functions
#' @export
HiveJob.scriptVariables <- function() {
    list()
}

#' HiveJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
#' 
#' 
#' 
#' @return HiveJob.properties object
#' 
#' @family HiveJob functions
#' @export
HiveJob.properties <- function() {
    list()
}

#' Empty Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance:service Foo {  rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty);}The JSON representation for Empty is empty JSON object {}.
#' 
#' 
#' 
#' @return Empty object
#' 
#' @family Empty functions
#' @export
Empty <- function() {
    list()
}

#' DiagnoseClusterResults Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The location of diagnostic output.
#' 
#' @param outputUri Output-only The Google Cloud Storage URI of the diagnostic output
#' 
#' @return DiagnoseClusterResults object
#' 
#' @family DiagnoseClusterResults functions
#' @export
DiagnoseClusterResults <- function(outputUri = NULL) {
    structure(list(outputUri = outputUri), class = "gar_DiagnoseClusterResults")
}

#' ClusterConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The cluster config.
#' 
#' @param initializationActions Optional Commands to execute on each node after config is completed
#' @param configBucket Optional A Google Cloud Storage staging bucket used for sharing generated SSH keys and config
#' @param workerConfig Optional The Google Compute Engine config settings for worker instances in a cluster
#' @param gceClusterConfig Required The shared Google Compute Engine config settings for all instances in a cluster
#' @param softwareConfig Optional The config settings for software inside the cluster
#' @param masterConfig Optional The Google Compute Engine config settings for the master instance in a cluster
#' @param secondaryWorkerConfig Optional The Google Compute Engine config settings for additional worker instances in a cluster
#' 
#' @return ClusterConfig object
#' 
#' @family ClusterConfig functions
#' @export
ClusterConfig <- function(initializationActions = NULL, configBucket = NULL, workerConfig = NULL, 
    gceClusterConfig = NULL, softwareConfig = NULL, masterConfig = NULL, secondaryWorkerConfig = NULL) {
    structure(list(initializationActions = initializationActions, configBucket = configBucket, 
        workerConfig = workerConfig, gceClusterConfig = gceClusterConfig, softwareConfig = softwareConfig, 
        masterConfig = masterConfig, secondaryWorkerConfig = secondaryWorkerConfig), 
        class = "gar_ClusterConfig")
}

#' PySparkJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache PySpark (https://spark.apache.org/docs/0.9.0/python-programming-guide.html) applications on YARN.
#' 
#' @param PySparkJob.properties The \link{PySparkJob.properties} object or list of objects
#' @param fileUris Optional HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks
#' @param pythonFileUris Optional HCFS file URIs of Python files to pass to the PySpark framework
#' @param mainPythonFileUri Required The HCFS URI of the main Python file to use as the driver
#' @param archiveUris Optional HCFS URIs of archives to be extracted in the working directory of 
#' @param jarFileUris Optional HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks
#' @param loggingConfig Optional The runtime log config for job execution
#' @param properties Optional A mapping of property names to values, used to configure PySpark
#' @param args Optional The arguments to pass to the driver
#' 
#' @return PySparkJob object
#' 
#' @family PySparkJob functions
#' @export
PySparkJob <- function(PySparkJob.properties = NULL, fileUris = NULL, pythonFileUris = NULL, 
    mainPythonFileUri = NULL, archiveUris = NULL, jarFileUris = NULL, loggingConfig = NULL, 
    properties = NULL, args = NULL) {
    structure(list(PySparkJob.properties = PySparkJob.properties, fileUris = fileUris, 
        pythonFileUris = pythonFileUris, mainPythonFileUri = mainPythonFileUri, archiveUris = archiveUris, 
        jarFileUris = jarFileUris, loggingConfig = loggingConfig, properties = properties, 
        args = args), class = "gar_PySparkJob")
}

#' PySparkJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
#' 
#' 
#' 
#' @return PySparkJob.properties object
#' 
#' @family PySparkJob functions
#' @export
PySparkJob.properties <- function() {
    list()
}

#' GceClusterConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Common config settings for resources of Google Compute Engine cluster instances, applicable to all instances in the cluster.
#' 
#' @param GceClusterConfig.metadata The \link{GceClusterConfig.metadata} object or list of objects
#' @param metadata The Google Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud
#' @param internalIpOnly Optional If true, all instances in the cluster will only have internal IP addresses
#' @param serviceAccountScopes Optional The URIs of service account scopes to be included in Google Compute Engine instances
#' @param tags The Google Compute Engine tags to add to all instances (see Tagging instances)
#' @param serviceAccount Optional The service account of the instances
#' @param subnetworkUri Optional The Google Compute Engine subnetwork to be used for machine communications
#' @param networkUri Optional The Google Compute Engine network to be used for machine communications
#' @param zoneUri Required The zone where the Google Compute Engine cluster will be located
#' 
#' @return GceClusterConfig object
#' 
#' @family GceClusterConfig functions
#' @export
GceClusterConfig <- function(GceClusterConfig.metadata = NULL, metadata = NULL, internalIpOnly = NULL, 
    serviceAccountScopes = NULL, tags = NULL, serviceAccount = NULL, subnetworkUri = NULL, 
    networkUri = NULL, zoneUri = NULL) {
    structure(list(GceClusterConfig.metadata = GceClusterConfig.metadata, metadata = metadata, 
        internalIpOnly = internalIpOnly, serviceAccountScopes = serviceAccountScopes, 
        tags = tags, serviceAccount = serviceAccount, subnetworkUri = subnetworkUri, 
        networkUri = networkUri, zoneUri = zoneUri), class = "gar_GceClusterConfig")
}

#' GceClusterConfig.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The Google Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
#' 
#' 
#' 
#' @return GceClusterConfig.metadata object
#' 
#' @family GceClusterConfig functions
#' @export
GceClusterConfig.metadata <- function() {
    list()
}

#' AcceleratorConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the type and number of accelerator cards attached to the instances of an instance group (see GPUs on Compute Engine).
#' 
#' @param acceleratorCount The number of the accelerator cards of this type exposed to this instance
#' @param acceleratorTypeUri Full or partial URI of the accelerator type resource to expose to this instance
#' 
#' @return AcceleratorConfig object
#' 
#' @family AcceleratorConfig functions
#' @export
AcceleratorConfig <- function(acceleratorCount = NULL, acceleratorTypeUri = NULL) {
    structure(list(acceleratorCount = acceleratorCount, acceleratorTypeUri = acceleratorTypeUri), 
        class = "gar_AcceleratorConfig")
}

#' ClusterMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Contains cluster daemon metrics, such as HDFS and YARN stats.Beta Feature: This report is available for testing purposes only. It may be changed before final release.
#' 
#' @param ClusterMetrics.yarnMetrics The \link{ClusterMetrics.yarnMetrics} object or list of objects
#' @param ClusterMetrics.hdfsMetrics The \link{ClusterMetrics.hdfsMetrics} object or list of objects
#' @param yarnMetrics The YARN metrics
#' @param hdfsMetrics The HDFS metrics
#' 
#' @return ClusterMetrics object
#' 
#' @family ClusterMetrics functions
#' @export
ClusterMetrics <- function(ClusterMetrics.yarnMetrics = NULL, ClusterMetrics.hdfsMetrics = NULL, 
    yarnMetrics = NULL, hdfsMetrics = NULL) {
    structure(list(ClusterMetrics.yarnMetrics = ClusterMetrics.yarnMetrics, ClusterMetrics.hdfsMetrics = ClusterMetrics.hdfsMetrics, 
        yarnMetrics = yarnMetrics, hdfsMetrics = hdfsMetrics), class = "gar_ClusterMetrics")
}

#' ClusterMetrics.yarnMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The YARN metrics.
#' 
#' 
#' 
#' @return ClusterMetrics.yarnMetrics object
#' 
#' @family ClusterMetrics functions
#' @export
ClusterMetrics.yarnMetrics <- function() {
    list()
}

#' ClusterMetrics.hdfsMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The HDFS metrics.
#' 
#' 
#' 
#' @return ClusterMetrics.hdfsMetrics object
#' 
#' @family ClusterMetrics functions
#' @export
ClusterMetrics.hdfsMetrics <- function() {
    list()
}

#' LoggingConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The runtime logging config of the job.
#' 
#' @param LoggingConfig.driverLogLevels The \link{LoggingConfig.driverLogLevels} object or list of objects
#' @param driverLogLevels The per-package log levels for the driver
#' 
#' @return LoggingConfig object
#' 
#' @family LoggingConfig functions
#' @export
LoggingConfig <- function(LoggingConfig.driverLogLevels = NULL, driverLogLevels = NULL) {
    structure(list(LoggingConfig.driverLogLevels = LoggingConfig.driverLogLevels, 
        driverLogLevels = driverLogLevels), class = "gar_LoggingConfig")
}

#' LoggingConfig.driverLogLevels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples:  'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
#' 
#' 
#' 
#' @return LoggingConfig.driverLogLevels object
#' 
#' @family LoggingConfig functions
#' @export
LoggingConfig.driverLogLevels <- function() {
    list()
}

#' DiagnoseClusterOutputLocation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The location where output from diagnostic command can be found.
#' 
#' @param outputUri Output-only The Google Cloud Storage URI of the diagnostic output
#' 
#' @return DiagnoseClusterOutputLocation object
#' 
#' @family DiagnoseClusterOutputLocation functions
#' @export
DiagnoseClusterOutputLocation <- function(outputUri = NULL) {
    structure(list(outputUri = outputUri), class = "gar_DiagnoseClusterOutputLocation")
}

#' Operation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' This resource represents a long-running operation that is the result of a network API call.
#' 
#' @param Operation.metadata The \link{Operation.metadata} object or list of objects
#' @param Operation.response The \link{Operation.response} object or list of objects
#' @param error The error result of the operation in case of failure or cancellation
#' @param metadata Service-specific metadata associated with the operation
#' @param done If the value is false, it means the operation is still in progress
#' @param response The normal response of the operation in case of success
#' @param name The server-assigned name, which is only unique within the same service that originally returns it
#' 
#' @return Operation object
#' 
#' @family Operation functions
#' @export
Operation <- function(Operation.metadata = NULL, Operation.response = NULL, error = NULL, 
    metadata = NULL, done = NULL, response = NULL, name = NULL) {
    structure(list(Operation.metadata = Operation.metadata, Operation.response = Operation.response, 
        error = error, metadata = metadata, done = done, response = response, name = name), 
        class = "gar_Operation")
}

#' Operation.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
#' 
#' 
#' 
#' @return Operation.metadata object
#' 
#' @family Operation functions
#' @export
Operation.metadata <- function() {
    list()
}

#' Operation.response Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The normal response of the operation in case of success. If the original method returns no data on success, such as Delete, the response is google.protobuf.Empty. If the original method is standard Get/Create/Update, the response should be the resource. For other methods, the response should have the type XxxResponse, where Xxx is the original method name. For example, if the original method name is TakeSnapshot(), the inferred response type is TakeSnapshotResponse.
#' 
#' 
#' 
#' @return Operation.response object
#' 
#' @family Operation functions
#' @export
Operation.response <- function() {
    list()
}

#' OperationStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of the operation.
#' 
#' @param innerState A message containing the detailed operation state
#' @param stateStartTime The time this state was entered
#' @param state A message containing the operation state
#' @param details A message containing any operation metadata details
#' 
#' @return OperationStatus object
#' 
#' @family OperationStatus functions
#' @export
OperationStatus <- function(innerState = NULL, stateStartTime = NULL, state = NULL, 
    details = NULL) {
    structure(list(innerState = innerState, stateStartTime = stateStartTime, state = state, 
        details = details), class = "gar_OperationStatus")
}

#' JobReference Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Encapsulates the full scoping used to reference a job.
#' 
#' @param projectId Required The ID of the Google Cloud Platform project that the job belongs to
#' @param jobId Optional The job ID, which must be unique within the project
#' 
#' @return JobReference object
#' 
#' @family JobReference functions
#' @export
JobReference <- function(projectId = NULL, jobId = NULL) {
    structure(list(projectId = projectId, jobId = jobId), class = "gar_JobReference")
}

#' SubmitJobRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to submit a job.
#' 
#' @param job Required The job resource
#' 
#' @return SubmitJobRequest object
#' 
#' @family SubmitJobRequest functions
#' @export
SubmitJobRequest <- function(job = NULL) {
    structure(list(job = job), class = "gar_SubmitJobRequest")
}

#' Status Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The Status type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by gRPC (https://github.com/grpc). The error model is designed to be:Simple to use and understand for most usersFlexible enough to meet unexpected needsOverviewThe Status message contains three pieces of data: error code, error message, and error details. The error code should be an enum value of google.rpc.Code, but it may accept additional error codes if needed. The error message should be a developer-facing English message that helps developers understand and resolve the error. If a localized user-facing error message is needed, put the localized message in the error details or localize it in the client. The optional error details may contain arbitrary information about the error. There is a predefined set of error detail types in the package google.rpc which can be used for common error conditions.Language mappingThe Status message is the logical representation of the error model, but it is not necessarily the actual wire format. When the Status message is exposed in different client libraries and different wire protocols, it can be mapped differently. For example, it will likely be mapped to some exceptions in Java, but more likely mapped to some error codes in C.Other usesThe error model and the Status message can be used in a variety of environments, either with or without APIs, to provide a consistent developer experience across different environments.Example uses of this error model include:Partial errors. If a service needs to return partial errors to the client, it may embed the Status in the normal response to indicate the partial errors.Workflow errors. A typical workflow has multiple steps. Each step may have a Status message for error reporting purpose.Batch operations. If a client uses batch request and batch response, the Status message should be used directly inside batch response, one for each error sub-response.Asynchronous operations. If an API call embeds asynchronous operation results in its response, the status of those operations should be represented directly using the Status message.Logging. If some API errors are stored in logs, the message Status could be used directly after any stripping needed for security/privacy reasons.
#' 
#' @param details A list of messages that carry the error details
#' @param code The status code, which should be an enum value of google
#' @param message A developer-facing error message, which should be in English
#' 
#' @return Status object
#' 
#' @family Status functions
#' @export
Status <- function(details = NULL, code = NULL, message = NULL) {
    structure(list(details = details, code = code, message = message), class = "gar_Status")
}

#' InstanceGroupConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional The config settings for Google Compute Engine resources in an instance group, such as a master or worker group.
#' 
#' @param diskConfig Optional Disk option config settings
#' @param managedGroupConfig Output-only The config for Google Compute Engine Instance Group Manager that manages this group
#' @param isPreemptible Optional Specifies that this instance group contains preemptible instances
#' @param imageUri Output-only The Google Compute Engine image resource used for cluster instances
#' @param machineTypeUri Required The Google Compute Engine machine type used for cluster instances
#' @param instanceNames Optional The list of instance names
#' @param accelerators Optional The Google Compute Engine accelerator configuration for these instances
#' @param numInstances Required The number of VM instances in the instance group
#' 
#' @return InstanceGroupConfig object
#' 
#' @family InstanceGroupConfig functions
#' @export
InstanceGroupConfig <- function(diskConfig = NULL, managedGroupConfig = NULL, isPreemptible = NULL, 
    imageUri = NULL, machineTypeUri = NULL, instanceNames = NULL, accelerators = NULL, 
    numInstances = NULL) {
    structure(list(diskConfig = diskConfig, managedGroupConfig = managedGroupConfig, 
        isPreemptible = isPreemptible, imageUri = imageUri, machineTypeUri = machineTypeUri, 
        instanceNames = instanceNames, accelerators = accelerators, numInstances = numInstances), 
        class = "gar_InstanceGroupConfig")
}

#' JobScheduling Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Job scheduling options.Beta Feature: These options are available for testing purposes only. They may be changed before final release.
#' 
#' @param maxFailuresPerHour Optional Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed
#' 
#' @return JobScheduling object
#' 
#' @family JobScheduling functions
#' @export
JobScheduling <- function(maxFailuresPerHour = NULL) {
    structure(list(maxFailuresPerHour = maxFailuresPerHour), class = "gar_JobScheduling")
}

#' NodeInitializationAction Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies an executable to run on a fully configured node and a timeout period for executable completion.
#' 
#' @param executionTimeout Optional Amount of time executable has to complete
#' @param executableFile Required Google Cloud Storage URI of executable file
#' 
#' @return NodeInitializationAction object
#' 
#' @family NodeInitializationAction functions
#' @export
NodeInitializationAction <- function(executionTimeout = NULL, executableFile = NULL) {
    structure(list(executionTimeout = executionTimeout, executableFile = executableFile), 
        class = "gar_NodeInitializationAction")
}

#' ListJobsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A list of jobs in a project.
#' 
#' @param jobs Output-only Jobs list
#' @param nextPageToken Optional This token is included in the response if there are more results to fetch
#' 
#' @return ListJobsResponse object
#' 
#' @family ListJobsResponse functions
#' @export
ListJobsResponse <- function(jobs = NULL, nextPageToken = NULL) {
    structure(list(jobs = jobs, nextPageToken = nextPageToken), class = "gar_ListJobsResponse")
}

#' CancelJobRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to cancel a job.
#' 
#' 
#' 
#' @return CancelJobRequest object
#' 
#' @family CancelJobRequest functions
#' @export
CancelJobRequest <- function() {
    list()
}

#' SparkSqlJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache Spark SQL (http://spark.apache.org/sql/) queries.
#' 
#' @param SparkSqlJob.scriptVariables The \link{SparkSqlJob.scriptVariables} object or list of objects
#' @param SparkSqlJob.properties The \link{SparkSqlJob.properties} object or list of objects
#' @param queryFileUri The HCFS URI of the script that contains SQL queries
#' @param queryList A list of queries
#' @param scriptVariables Optional Mapping of query variable names to values (equivalent to the Spark SQL command: SET name='value';)
#' @param jarFileUris Optional HCFS URIs of jar files to be added to the Spark CLASSPATH
#' @param loggingConfig Optional The runtime log config for job execution
#' @param properties Optional A mapping of property names to values, used to configure Spark SQL's SparkConf
#' 
#' @return SparkSqlJob object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob <- function(SparkSqlJob.scriptVariables = NULL, SparkSqlJob.properties = NULL, 
    queryFileUri = NULL, queryList = NULL, scriptVariables = NULL, jarFileUris = NULL, 
    loggingConfig = NULL, properties = NULL) {
    structure(list(SparkSqlJob.scriptVariables = SparkSqlJob.scriptVariables, SparkSqlJob.properties = SparkSqlJob.properties, 
        queryFileUri = queryFileUri, queryList = queryList, scriptVariables = scriptVariables, 
        jarFileUris = jarFileUris, loggingConfig = loggingConfig, properties = properties), 
        class = "gar_SparkSqlJob")
}

#' SparkSqlJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional Mapping of query variable names to values (equivalent to the Spark SQL command: SET name='value';).
#' 
#' 
#' 
#' @return SparkSqlJob.scriptVariables object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob.scriptVariables <- function() {
    list()
}

#' SparkSqlJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
#' 
#' 
#' 
#' @return SparkSqlJob.properties object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob.properties <- function() {
    list()
}

#' Cluster Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Describes the identifying information, config, and status of a cluster of Google Compute Engine instances.
#' 
#' @param Cluster.labels The \link{Cluster.labels} object or list of objects
#' @param labels Optional The labels to associate with this cluster
#' @param metrics Contains cluster daemon metrics such as HDFS and YARN stats
#' @param status Output-only Cluster status
#' @param config Required The cluster config
#' @param statusHistory Output-only The previous cluster status
#' @param clusterName Required The cluster name
#' @param clusterUuid Output-only A cluster UUID (Unique Universal Identifier)
#' @param projectId Required The Google Cloud Platform project ID that the cluster belongs to
#' 
#' @return Cluster object
#' 
#' @family Cluster functions
#' @export
Cluster <- function(Cluster.labels = NULL, labels = NULL, metrics = NULL, status = NULL, 
    config = NULL, statusHistory = NULL, clusterName = NULL, clusterUuid = NULL, 
    projectId = NULL) {
    structure(list(Cluster.labels = Cluster.labels, labels = labels, metrics = metrics, 
        status = status, config = config, statusHistory = statusHistory, clusterName = clusterName, 
        clusterUuid = clusterUuid, projectId = projectId), class = "gar_Cluster")
}

#' Cluster.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional The labels to associate with this cluster. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a cluster.
#' 
#' 
#' 
#' @return Cluster.labels object
#' 
#' @family Cluster functions
#' @export
Cluster.labels <- function() {
    list()
}

#' ListOperationsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The response message for Operations.ListOperations.
#' 
#' @param nextPageToken The standard List next-page token
#' @param operations A list of operations that matches the specified filter in the request
#' 
#' @return ListOperationsResponse object
#' 
#' @family ListOperationsResponse functions
#' @export
ListOperationsResponse <- function(nextPageToken = NULL, operations = NULL) {
    structure(list(nextPageToken = nextPageToken, operations = operations), class = "gar_ListOperationsResponse")
}

#' OperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata describing the operation.
#' 
#' @param operationType Output-only The operation type
#' @param description Output-only Short description of operation
#' @param status Output-only Current operation status
#' @param state A message containing the operation state
#' @param details A message containing any operation metadata details
#' @param clusterName Name of the cluster for the operation
#' @param clusterUuid Cluster UUId for the operation
#' @param innerState A message containing the detailed operation state
#' @param endTime The time that the operation completed
#' @param startTime The time that the operation was started by the server
#' @param warnings Output-only Errors encountered during operation execution
#' @param insertTime The time that the operation was requested
#' @param statusHistory Output-only Previous operation status
#' 
#' @return OperationMetadata object
#' 
#' @family OperationMetadata functions
#' @export
OperationMetadata <- function(operationType = NULL, description = NULL, status = NULL, 
    state = NULL, details = NULL, clusterName = NULL, clusterUuid = NULL, innerState = NULL, 
    endTime = NULL, startTime = NULL, warnings = NULL, insertTime = NULL, statusHistory = NULL) {
    structure(list(operationType = operationType, description = description, status = status, 
        state = state, details = details, clusterName = clusterName, clusterUuid = clusterUuid, 
        innerState = innerState, endTime = endTime, startTime = startTime, warnings = warnings, 
        insertTime = insertTime, statusHistory = statusHistory), class = "gar_OperationMetadata")
}

#' JobPlacement Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Cloud Dataproc job config.
#' 
#' @param clusterName Required The name of the cluster where the job will be submitted
#' @param clusterUuid Output-only A cluster UUID generated by the Cloud Dataproc service when the job is submitted
#' 
#' @return JobPlacement object
#' 
#' @family JobPlacement functions
#' @export
JobPlacement <- function(clusterName = NULL, clusterUuid = NULL) {
    structure(list(clusterName = clusterName, clusterUuid = clusterUuid), class = "gar_JobPlacement")
}

#' SoftwareConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the selection and config of software inside the cluster.
#' 
#' @param SoftwareConfig.properties The \link{SoftwareConfig.properties} object or list of objects
#' @param imageVersion Optional The version of software inside the cluster
#' @param properties Optional The properties to set on daemon config files
#' 
#' @return SoftwareConfig object
#' 
#' @family SoftwareConfig functions
#' @export
SoftwareConfig <- function(SoftwareConfig.properties = NULL, imageVersion = NULL, 
    properties = NULL) {
    structure(list(SoftwareConfig.properties = SoftwareConfig.properties, imageVersion = imageVersion, 
        properties = properties), class = "gar_SoftwareConfig")
}

#' SoftwareConfig.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional The properties to set on daemon config files.Property keys are specified in prefix:property format, such as core:fs.defaultFS. The following are supported prefixes and their mappings:core: core-site.xmlhdfs: hdfs-site.xmlmapred: mapred-site.xmlyarn: yarn-site.xmlhive: hive-site.xmlpig: pig.propertiesspark: spark-defaults.conf
#' 
#' 
#' 
#' @return SoftwareConfig.properties object
#' 
#' @family SoftwareConfig functions
#' @export
SoftwareConfig.properties <- function() {
    list()
}

#' ClusterStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of a cluster and its instances.
#' 
#' @param detail Output-only Optional details of cluster's state
#' @param state Output-only The cluster's state
#' @param stateStartTime Output-only Time when this state was entered
#' 
#' @return ClusterStatus object
#' 
#' @family ClusterStatus functions
#' @export
ClusterStatus <- function(detail = NULL, state = NULL, stateStartTime = NULL) {
    structure(list(detail = detail, state = state, stateStartTime = stateStartTime), 
        class = "gar_ClusterStatus")
}

#' PigJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Apache Pig (https://pig.apache.org/) queries on YARN.
#' 
#' @param PigJob.properties The \link{PigJob.properties} object or list of objects
#' @param PigJob.scriptVariables The \link{PigJob.scriptVariables} object or list of objects
#' @param properties Optional A mapping of property names to values, used to configure Pig
#' @param continueOnFailure Optional Whether to continue executing queries if a query fails
#' @param queryList A list of queries
#' @param queryFileUri The HCFS URI of the script that contains the Pig queries
#' @param jarFileUris Optional HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks
#' @param scriptVariables Optional Mapping of query variable names to values (equivalent to the Pig command: name=[value])
#' @param loggingConfig Optional The runtime log config for job execution
#' 
#' @return PigJob object
#' 
#' @family PigJob functions
#' @export
PigJob <- function(PigJob.properties = NULL, PigJob.scriptVariables = NULL, properties = NULL, 
    continueOnFailure = NULL, queryList = NULL, queryFileUri = NULL, jarFileUris = NULL, 
    scriptVariables = NULL, loggingConfig = NULL) {
    structure(list(PigJob.properties = PigJob.properties, PigJob.scriptVariables = PigJob.scriptVariables, 
        properties = properties, continueOnFailure = continueOnFailure, queryList = queryList, 
        queryFileUri = queryFileUri, jarFileUris = jarFileUris, scriptVariables = scriptVariables, 
        loggingConfig = loggingConfig), class = "gar_PigJob")
}

#' PigJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
#' 
#' 
#' 
#' @return PigJob.properties object
#' 
#' @family PigJob functions
#' @export
PigJob.properties <- function() {
    list()
}


#' PigJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional Mapping of query variable names to values (equivalent to the Pig command: name=[value]).
#' 
#' 
#' 
#' @return PigJob.scriptVariables object
#' 
#' @family PigJob functions
#' @export


PigJob.scriptVariables <- function() {
    
    
    list()
    
}

