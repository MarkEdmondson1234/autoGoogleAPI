% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataproc_objects.R
\name{SparkJob}
\alias{SparkJob}
\title{SparkJob Object}
\usage{
SparkJob(SparkJob.properties = NULL, loggingConfiguration = NULL,
  properties = NULL, args = NULL, fileUris = NULL, mainClass = NULL,
  archiveUris = NULL, mainJarFileUri = NULL, jarFileUris = NULL)
}
\arguments{
\item{SparkJob.properties}{The \link{SparkJob.properties} object or list of objects}

\item{loggingConfiguration}{Optional The runtime log configuration for job execution}

\item{properties}{Optional A mapping of property names to values, used to configure Spark}

\item{args}{Optional The arguments to pass to the driver}

\item{fileUris}{Optional HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks}

\item{mainClass}{The name of the driver's main class}

\item{archiveUris}{Optional HCFS URIs of archives to be extracted in the working directory of Spark drivers and tasks}

\item{mainJarFileUri}{The Hadoop Compatible Filesystem (HCFS) URI of the jar file that contains the main class}

\item{jarFileUris}{Optional HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks}
}
\value{
SparkJob object
}
\description{
SparkJob Object
}
\details{
Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
A Cloud Dataproc job for running Spark applications on YARN.
}
\seealso{
Other SparkJob functions: \code{\link{SparkJob.properties}}
}
